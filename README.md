Hi there, I'm Harshal Hirpara! 👋  
===============================  
I'm an aspiring 🚀 ML engineer and M.S. Computer Science student @ University of Illinois Chicago 🌆

I love building intelligent systems to solve real-world problems with cutting-edge technology. 💡

#### 🔥 Superpowers Unleashed:
* **Programming Mastery**: Python (NumPy, Pandas, Scikit-learn, TensorFlow, PyTorch, Keras), Java, C++, and Scala.
* **Machine Learning Expertise**: Deep Learning, Natural Language Processing, Computer Vision, Reinforcement Learning, Gradient Boosting.
* **Data & Cloud Proficiency**: Hadoop, Spark, MongoDB, PostgreSQL, AWS (SageMaker, Lambda, EC2), GCP, Azure, Docker, Kubernetes, Terraform.
* **AI & Model Development**: Expertise in LLMs, neural networks, and deploying scalable ML models.

#### 🚀 Adventures in AI (Work Experience):
* **Graduate Research Assistant** - University of Illinois at Chicago (Aug 2024 - Present)  
  * Enhanced user preference-based generation quality for Large Language Models (LLMs) by developing novel methods for alignment.
  * Developed an Offline Reinforcement Learning model to recommend optimal treatment actions for a digital twin of a cancer patient.
  * **Tech Stack**: Python, PyTorch, RL-Gym.

* **Graduate Researcher** - UI Health, Neurology and Rehabilitation Dept. (Oct 2023 - Present)  
  * Deployed a scalable ML pipeline reducing EEG signal analysis processing time by 40%.
  * Achieved state-of-the-art detection with 99% accuracy, 88% sensitivity, and 0.43 false positives per hour.
  * **Tech Stack**: Python, JAX, SciPy, Azure ML Studio.

* **Machine Learning Intern** - Cactus Communications (Jan 2023 - Jul 2023)  
  * Reduced operational costs by $10K annually by optimizing GPT-3.5 API usage, and improved system reliability by 15%.
  * Created a text extraction and keyword generation tool using Huggingface transformers to aid scientific writing.
  * **Tech Stack**: Python, PyTorch, AWS (EC2, Inferentia), Docker, Terraform.

#### 📝 Recent Medium Article:
* **Exploring Large Language Models: Concepts, Alignment Techniques, and Practical Implementation** 📝  
  In this article, I delve into training methods for large language models and alignment techniques, including practical implementations of LoRA, QLoRA, and RLHF. Check it out [here](https://medium.com/@hhirp/exploring-large-language-models-concepts-alignment-techniques-and-practical-implementation-8279aaa2f91f).  
  For more of my writing, visit my [Medium](https://medium.com/@hhirp).

#### 🎯 Projects I'm Proud Of:
* **LLM-Grounded Text-In-Image Generation** 🖼️: Leveraged Llama 16B to generate conditional masks of text within images, utilizing a custom dataset and advanced model optimization techniques.
* **Ambulatory EEG Signal Analysis** 🧠: Reduced EEG signal processing time by 40% with a scalable ML pipeline. Achieved 99% accuracy and 88% sensitivity in EEG anomaly detection.
* **SCIPASUMM** 📜: Working on an end-to-end research paper summarization pipeline using NLP techniques like Bart-ls.
* **Emotion Recognition with Face Mask** 😷: Created a CNN to classify emotions from masked faces using OpenCV and Keras.
* **Lithium-Ion Battery** 🔋: Built a forecasting model using TensorFlow to estimate battery capacity. Achieved ≤4% error!
* **Robotic Arm** 🤖: Trained a simulated robotic arm to grab objects using reinforcement learning algorithms.
* **Plant Disease Classification** 🌱: Developed an image classifier using ResNet to identify 38 plant diseases accurately. 🌳

There's so much more I'm learning and building as an aspiring ML engineer. [Let's connect on LinkedIn!](https://www.linkedin.com/in/harshaljhirpara) I'm always happy to network with others who are passionate about AI. 😊
